# ============================================================================
# shared-utilities/data_science/examples_advanced.py - EXAM FOCUSED
# ============================================================================
"""
×“×•×’×××•×ª ××ª×§×“××•×ª ××ª××§×“×•×ª ×‘×ª×¨×—×™×©×™ ××‘×—×Ÿ × ×¤×•×¦×™×
×›×œ ×“×•×’××” ××ª××™××” ×œ×©××œ×” ××¤×©×¨×™×ª ×‘××‘×—×Ÿ
"""

import pandas as pd
from datetime import datetime
import logging

# Import everything we might need
from . import *

logger = logging.getLogger(__name__)


# ============================================================================
# ×“×•×’××” 1: ×”××‘×—×Ÿ ×“×•×¨×© ×¡×¤×¨×™×™×” ×¡×¤×¦×™×¤×™×ª
# ============================================================================

def exam_scenario_specific_library():
    """
    ×ª×¨×—×™×© ××‘×—×Ÿ: "×”×©×ª××© ×‘-TextBlob ×œ× ×™×ª×•×— ×¨×’×©×•×ª"
    ××” ×œ×¢×©×•×ª ×›×©×”××‘×—×Ÿ ×“×•×¨×© ×¡×¤×¨×™×™×” ×¡×¤×¦×™×¤×™×ª
    """
    print("=== ×ª×¨×—×™×© ××‘×—×Ÿ: ×¡×¤×¨×™×™×” ×¡×¤×¦×™×¤×™×ª ===")

    exam_text = "I absolutely love this new smartphone! The camera quality is amazing."

    # 1. × ×™×¡×™×•×Ÿ ×œ×”×©×ª××© ×‘×¡×¤×¨×™×™×” ×”××‘×•×§×©×ª
    print("1. ×”××‘×—×Ÿ ×“×•×¨×©: TextBlob")

    try:
        # × ×¡×” TextBlob ×¡×¤×¦×™×¤×™
        analyzer = ProcessorFactory.create_sentiment_analyzer("textblob")
        result = analyzer.analyze_sentiment(exam_text)
        print(f"   âœ… TextBlob ×–××™×Ÿ: {result['label']} ({result['compound']:.3f})")
        analyzer_used = "textblob"

    except Exception as e:
        print(f"   âŒ TextBlob ×œ× ×–××™×Ÿ: {e}")

        # 2. Fallback ×œ×–××™×Ÿ
        print("2. ×¢×•×‘×¨ ×œ-fallback ××•×˜×•××˜×™:")
        analyzer = SmartSentimentAnalyzer()
        result = analyzer.analyze_sentiment(exam_text)
        analyzer_used = result.get('analyzer', 'unknown')
        print(f"   âœ… ×”×©×ª××© ×‘-{analyzer_used}: {result['label']} ({result['compound']:.3f})")

    # 3. ×”×¦×’ ××” ×–××™×Ÿ ×‘××¢×¨×›×ª
    available = get_available_sentiment_analyzers()
    print(f"3. ×¡×¤×¨×™×•×ª ×–××™× ×•×ª ×‘××¢×¨×›×ª: {available}")

    return result, analyzer_used


# ============================================================================
# ×“×•×’××” 2: Stemming ×•-Lemmatization (× ×•×©× ×¤×•×¤×•×œ×¨×™ ×‘××‘×—× ×™×)
# ============================================================================

def exam_scenario_stemming_lemmatization():
    """
    ×ª×¨×—×™×© ××‘×—×Ÿ: "×‘×¦×¢ stemming ×•-lemmatization ×œ×˜×§×¡×˜"
    ×”×“×’××ª ×™×›×•×œ×•×ª NLP ××ª×§×“××•×ª
    """
    print("\n=== ×ª×¨×—×™×© ××‘×—×Ÿ: Stemming & Lemmatization ===")

    exam_text = "The running dogs are quickly eating delicious foods"
    print(f"×˜×§×¡×˜ ×œ× ×™×ª×•×—: '{exam_text}'")

    # 1. × ×™×¡×™×•×Ÿ ×¢× NLTK
    print("\n1. ×¢× NLTK:")
    try:
        nltk_processor = NLTKTextProcessor()

        tokens = nltk_processor.tokenize(exam_text)
        stems = nltk_processor.extract_stems(exam_text)
        lemmas = nltk_processor.extract_lemmas(exam_text)

        print(f"   Tokens: {tokens}")
        print(f"   Stems: {stems}")
        print(f"   Lemmas: {lemmas}")

    except Exception as e:
        print(f"   âŒ NLTK ×œ× ×–××™×Ÿ: {e}")

    # 2. × ×™×¡×™×•×Ÿ ×¢× spaCy
    print("\n2. ×¢× spaCy:")
    try:
        spacy_processor = SpaCyTextProcessor()

        tokens = spacy_processor.tokenize(exam_text)
        lemmas = spacy_processor.extract_lemmas(exam_text)
        roots = spacy_processor.extract_roots(exam_text)

        print(f"   Tokens: {tokens}")
        print(f"   Lemmas: {lemmas}")
        print(f"   Roots: {roots}")

    except Exception as e:
        print(f"   âŒ spaCy ×œ× ×–××™×Ÿ: {e}")

    # 3. Fallback ×‘×¡×™×¡×™ (×ª××™×“ ×¢×•×‘×“)
    print("\n3. Fallback ×‘×¡×™×¡×™:")
    basic_processor = BasicTextProcessor()

    tokens = basic_processor.tokenize(exam_text)
    stems = basic_processor.extract_stems(exam_text)
    lemmas = basic_processor.extract_lemmas(exam_text)

    print(f"   Tokens: {tokens}")
    print(f"   Stems: {stems}")
    print(f"   Lemmas: {lemmas}")


# ============================================================================
# ×“×•×’××” 3: ×¢×™×‘×•×“ ×¢×‘×¨×™×ª (×—×©×•×‘ ×œ×™×©×¨××œ)
# ============================================================================

def exam_scenario_hebrew_processing():
    """
    ×ª×¨×—×™×© ××‘×—×Ÿ: "× ×ª×— ×˜×§×¡×˜ ×‘×¢×‘×¨×™×ª"
    ×”×“×’××ª ×™×›×•×œ×•×ª ×¢×™×‘×•×“ ×¢×‘×¨×™×ª ××ª×§×“××•×ª
    """
    print("\n=== ×ª×¨×—×™×© ××‘×—×Ÿ: ×¢×™×‘×•×“ ×¢×‘×¨×™×ª ===")

    hebrew_texts = [
        "×”××•×¦×¨ ×”×–×” ××¢×•×œ×” ×•××•××œ×¥ ×‘×—×•×",
        "×”×©×™×¨×•×ª ×”×™×” ×¨×¢ ×•×××›×–×‘ ×××•×“",
        "×× ×™ ×××•×“ ××¨×•×¦×” ××”×§× ×™×™×” ×”×—×“×©×”",
        "×”×˜×›× ×•×œ×•×’×™×” ×”×—×“×©×” ××“×”×™××”"
    ]

    hebrew_processor = HebrewTextProcessor()
    hebrew_sentiment = HebrewSentimentAnalyzer()

    print("× ×™×ª×•×— ×˜×§×¡×˜×™× ×‘×¢×‘×¨×™×ª:")
    for i, text in enumerate(hebrew_texts, 1):
        print(f"\n{i}. '{text}'")

        # ×˜×•×§× ×™×–×¦×™×”
        tokens = hebrew_processor.tokenize(text)
        print(f"   ×˜×•×§× ×™×: {tokens}")

        # ×—×™×œ×•×¥ stems ×•-roots
        stems = hebrew_processor.extract_stems(text)
        roots = hebrew_processor.extract_roots(text)
        print(f"   Stems: {stems}")
        print(f"   Roots: {roots}")

        # × ×™×ª×•×— ×¨×’×©×•×ª
        sentiment = hebrew_sentiment.analyze_sentiment(text)
        print(f"   ×¨×’×©: {sentiment['label']} (×¦×™×•×Ÿ: {sentiment['compound']:.3f})")


# ============================================================================
# ×“×•×’××” 4: ×”×©×•×•××ª ××•×“×œ×™× (×××™×Ÿ ×œ××‘×—×Ÿ)
# ============================================================================

def exam_scenario_model_comparison():
    """
    ×ª×¨×—×™×© ××‘×—×Ÿ: "×”×©×•×•×” ×‘×™×Ÿ ××•×“×œ×™× ×©×•× ×™×"
    ×”×“×’××ª Ensemble ×•-Multi-model
    """
    print("\n=== ×ª×¨×—×™×© ××‘×—×Ÿ: ×”×©×•×•××ª ××•×“×œ×™× ===")

    test_sentences = [
        "This product is absolutely amazing!",
        "Terrible quality, very disappointed.",
        "It's okay, nothing special.",
        "Outstanding service and fast delivery!"
    ]

    print("×”×©×•×•××ª analyzers ×¢×œ ×˜×§×¡×˜×™× ×©×•× ×™×:")

    for i, sentence in enumerate(test_sentences, 1):
        print(f"\n{i}. '{sentence}'")

        # ×‘×“×™×§×” ×¢× analyzers ×©×•× ×™×
        analyzers_to_test = ["vader", "textblob", "fallback", "smart"]

        results = {}
        for analyzer_name in analyzers_to_test:
            try:
                if analyzer_name == "smart":
                    analyzer = SmartSentimentAnalyzer()
                else:
                    analyzer = ProcessorFactory.create_sentiment_analyzer(analyzer_name)

                result = analyzer.analyze_sentiment(sentence)
                results[analyzer_name] = result

                print(f"   {analyzer_name:8}: {result['label']:8} ({result['compound']:+.3f})")

            except Exception as e:
                print(f"   {analyzer_name:8}: âŒ ×œ× ×–××™×Ÿ")
                results[analyzer_name] = None

        # Ensemble (×× ×™×© ×›××” analyzers ×–××™× ×™×)
        try:
            available_analyzers = [name for name, result in results.items() if result is not None]
            if len(available_analyzers) >= 2:
                ensemble = EnsembleSentimentAnalyzer(available_analyzers[:3])
                ensemble_result = ensemble.analyze_sentiment(sentence)
                print(f"   ensemble : {ensemble_result['label']:8} ({ensemble_result['compound']:+.3f}) [×××•×¦×¢]")
        except:
            print("   ensemble : âŒ ×œ× ×–××™×Ÿ")


# ============================================================================
# ×“×•×’××” 5: Pipeline ××œ× ×œ××‘×—×Ÿ
# ============================================================================

def exam_scenario_complete_pipeline():
    """
    ×ª×¨×—×™×© ××‘×—×Ÿ: "×‘×¦×¢ × ×™×ª×•×— ×˜×§×¡×˜ ××œ×"
    Pipeline ×©×œ× ××˜×¢×™× ×ª ×§×•×‘×¥ ×¢×“ ×ª×•×¦××•×ª
    """
    print("\n=== ×ª×¨×—×™×© ××‘×—×Ÿ: Pipeline ××œ× ===")

    # ×™×¦×™×¨×ª × ×ª×•× ×™ ×“×•×’××” ×œ××‘×—×Ÿ
    sample_data = pd.DataFrame({
        'review_text': [
            "This laptop is amazing! Great performance and battery life.",
            "Poor quality product. Broke after one week of use.",
            "Average phone, nothing extraordinary but functional.",
            "Excellent customer service and fast shipping!",
            "Overpriced for what you get. Not recommended.",
            "Perfect for students. Lightweight and reliable.",
            "Terrible experience. Product arrived damaged.",
            "Good value for money. Satisfied with purchase.",
            "Outstanding quality! Exceeded my expectations.",
            "Okay product but could be better for the price."
        ],
        'product_category': ['laptop', 'electronics', 'phone', 'service', 'electronics',
                             'laptop', 'shipping', 'electronics', 'electronics', 'electronics'],
        'rating': [5, 1, 3, 5, 2, 4, 1, 4, 5, 3]
    })

    print(f"1. × ×ª×•× ×™ ×“×•×’××”: {len(sample_data)} ×‘×™×§×•×¨×•×ª")

    # Pipeline ×‘×¡×™×¡×™
    print("\n2. Pipeline ×‘×¡×™×¡×™:")
    try:
        results = quick_text_analysis_pipeline(
            data=sample_data,  # ×× ×™×© data ×‘××§×•× file_path
            text_column="review_text",
            category_column="product_category"
        )

        processing_info = results.get('processing_info', {})
        print(f"   âœ… Pipeline ×”×•×©×œ× ×‘×”×¦×œ×—×”")
        print(f"   ××¢×‘×“ ×¨×’×©×•×ª: {processing_info.get('analyzer_used', 'unknown')}")
        print(f"   ×˜×§×¡×˜×™× ××¢×•×‘×“×™×: {processing_info.get('final_rows', 0)}")

        # ×”×¦×’ ×ª×•×¦××•×ª
        if 'cleaned_data' in results:
            df_result = results['cleaned_data']
            sentiment_dist = df_result['sentiment_label'].value_counts()
            print(f"   ×”×ª×¤×œ×’×•×ª ×¨×’×©×•×ª: {sentiment_dist.to_dict()}")

    except Exception as e:
        print(f"   âŒ Pipeline ×‘×¡×™×¡×™ × ×›×©×œ: {e}")

    # Pipeline ××ª×§×“× ×¢× ×”×’×“×¨×•×ª
    print("\n3. Pipeline ××ª×§×“×:")
    try:
        # ×™×¦×™×¨×ª ×”×’×“×¨×•×ª ×‘×˜×•×—×•×ª ×œ××‘×—×Ÿ
        config = create_exam_safe_pipeline(preferred_sentiment="vader")
        print(f"   ×”×’×“×¨×•×ª ×‘×˜×•×—×•×ª: {config.to_dict() if config else 'basic fallback'}")

        # × ×™×ª×•×— ×™×“× ×™ ×¢× smart analyzers
        smart_analyzer = SmartSentimentAnalyzer()
        smart_processor = SmartTextProcessor()

        print(f"   Smart analyzer ×–××™×Ÿ: {smart_analyzer.get_available_analyzers()}")
        print(f"   Smart processor ×–××™×Ÿ: {smart_processor.get_supported_languages()}")

    except Exception as e:
        print(f"   âŒ Pipeline ××ª×§×“× × ×›×©×œ: {e}")


# ============================================================================
# ×“×•×’××” 6: ×‘×¢×™×•×ª × ×¤×•×¦×•×ª ×•×¤×ª×¨×•× ×•×ª ×œ××‘×—×Ÿ
# ============================================================================

def exam_scenario_troubleshooting():
    """
    ×ª×¨×—×™×© ××‘×—×Ÿ: "×¤×ª×¨×•×Ÿ ×‘×¢×™×•×ª × ×¤×•×¦×•×ª"
    ××™×š ×œ×”×ª××•×“×“ ×¢× ×‘×¢×™×•×ª ×©×™×›×•×œ×•×ª ×œ×§×¨×•×ª ×‘××‘×—×Ÿ
    """
    print("\n=== ×ª×¨×—×™×© ××‘×—×Ÿ: ×¤×ª×¨×•×Ÿ ×‘×¢×™×•×ª ===")

    # ×‘×¢×™×” 1: ×§×•×‘×¥ ×œ× × ××¦×
    print("1. ×˜×™×¤×•×œ ×‘×§×•×‘×¥ ×©×œ× × ××¦×:")
    try:
        loader = UniversalDataLoader()
        df = loader.load_data("nonexistent_file.csv")
    except FileNotFoundError:
        print("   âœ… ×–×•×”×” ×§×•×‘×¥ ×©×œ× × ××¦× - ×”×˜×™×¤×•×œ ×ª×§×™×Ÿ")
        # ×¤×ª×¨×•×Ÿ: ×™×¦×™×¨×ª × ×ª×•× ×™ ×“×•×’××”
        df = pd.DataFrame({
            'text': ['sample text for demo'],
            'category': ['demo']
        })
        print("   âœ… × ×•×¦×¨×• × ×ª×•× ×™ ×“×•×’××” ×‘××§×•×")

    # ×‘×¢×™×” 2: ×¢××•×“×” ×©×œ× ×§×™×™××ª
    print("\n2. ×˜×™×¤×•×œ ×‘×¢××•×“×” ×©×œ× ×§×™×™××ª:")
    if 'nonexistent_column' not in df.columns:
        print("   âœ… ×–×•×”×” ×¢××•×“×” ×©×œ× ×§×™×™××ª")
        print(f"   ×¢××•×“×•×ª ×–××™× ×•×ª: {list(df.columns)}")
        text_column = df.columns[0]  # ×”×©×ª××© ×‘×¢××•×“×” ×”×¨××©×•× ×”
        print(f"   âœ… ×”×©×ª××© ×‘×¢××•×“×”: {text_column}")

    # ×‘×¢×™×” 3: ×¡×¤×¨×™×™×” ×—×¡×¨×”
    print("\n3. ×˜×™×¤×•×œ ×‘×¡×¤×¨×™×™×” ×—×¡×¨×”:")
    try:
        # × ×¡×” ×¡×¤×¨×™×™×” ×©×œ× ×§×™×™××ª
        analyzer = ProcessorFactory.create_sentiment_analyzer("nonexistent_analyzer")
    except (ValueError, Exception) as e:
        print(f"   âœ… ×–×•×”×” ×¡×¤×¨×™×™×” ×—×¡×¨×”: {type(e).__name__}")
        # ×¤×ª×¨×•×Ÿ: fallback
        analyzer = FallbackSentimentAnalyzer()
        print("   âœ… ×¢×‘×¨ ×œ-fallback analyzer")

        # ×‘×“×™×§×” ×©×”×•× ×¢×•×‘×“
        result = analyzer.analyze_sentiment("test text")
        print(f"   âœ… Fallback ×¢×•×‘×“: {result['label']}")

    # ×‘×¢×™×” 4: ×˜×§×¡×˜ ×¨×™×§
    print("\n4. ×˜×™×¤×•×œ ×‘×˜×§×¡×˜ ×¨×™×§:")
    empty_texts = ["", None, "   ", "###"]
    cleaner = TextCleaner()

    for i, empty_text in enumerate(empty_texts):
        cleaned = cleaner.clean_text(str(empty_text) if empty_text else "")
        print(f"   ×˜×§×¡×˜ {i + 1}: '{empty_text}' â†’ '{cleaned}'")

    print("   âœ… ×˜×™×¤×•×œ ×‘×˜×§×¡×˜×™× ×¨×™×§×™× ×ª×§×™×Ÿ")


# ============================================================================
# ×“×•×’××” 7: ×ª×›×•× ×•×ª ××ª×§×“××•×ª ×œ××‘×—×Ÿ ××§×¦×•×¢×™
# ============================================================================

def exam_scenario_advanced_features():
    """
    ×ª×¨×—×™×© ××‘×—×Ÿ: "×”×©×ª××© ×‘×ª×›×•× ×•×ª ××ª×§×“××•×ª"
    ×”×“×’××ª ×™×›×•×œ×•×ª ××ª×§×“××•×ª ×œ×¦×™×•×Ÿ ×’×‘×•×”
    """
    print("\n=== ×ª×¨×—×™×© ××‘×—×Ÿ: ×ª×›×•× ×•×ª ××ª×§×“××•×ª ===")

    # 1. ×—×™×œ×•×¥ ×ª×›×•× ×•×ª ××œ×
    print("1. ×—×™×œ×•×¥ ×ª×›×•× ×•×ª ××œ×:")
    sample_text = "The innovative technology is revolutionizing industries"

    features = extract_all_features(sample_text)
    for feature_name, feature_value in features.items():
        if isinstance(feature_value, list):
            print(f"   {feature_name}: {feature_value[:5]}...")  # ×”×¦×’ 5 ×¨××©×•× ×™×
        elif isinstance(feature_value, dict):
            print(f"   {feature_name}: {feature_value.get('label', 'N/A')} ({feature_value.get('compound', 0):.3f})")
        else:
            print(f"   {feature_name}: {feature_value}")

    # 2. × ×™×ª×•×— ×‘×–××Ÿ ×××ª
    print("\n2. × ×™×ª×•×— ××”×™×¨ ×œ×˜×§×¡×˜×™× ×©×•× ×™×:")
    quick_tests = [
        "Excellent product quality!",
        "Disappointing experience overall.",
        "Average performance, nothing special."
    ]

    for text in quick_tests:
        result = quick_sentiment_check(text, analyzer="auto")
        print(f"   '{text[:30]}...' â†’ {result['label']} ({result.get('compound', 0):+.3f})")

    # 3. ×¡×˜×˜×™×¡×˜×™×§×•×ª ××ª×§×“××•×ª
    print("\n3. ×¡×˜×˜×™×¡×˜×™×§×•×ª ××ª×§×“××•×ª:")
    sample_df = pd.DataFrame({
        'text': [
            "Amazing product with great features!",
            "Poor quality, not recommended at all.",
            "Good value for the price point.",
            "Outstanding customer service experience!",
            "Average product, meets basic needs."
        ],
        'category': ['electronics', 'electronics', 'electronics', 'service', 'electronics']
    })

    # × ×™×ª×•×— ××”×™×¨
    analyzer = SentimentAnalyzer()
    df_analyzed = analyzer.analyze_dataframe(sample_df, 'text')

    # ×—×™×©×•×‘ ×¡×˜×˜×™×¡×˜×™×§×•×ª
    scores = df_analyzed['sentiment_score'].tolist()
    stats = analyzer.get_sentiment_statistics(scores)

    print(f"   ×××•×¦×¢ ×¨×’×©×•×ª: {stats['average_score']}")
    print(
        f"   ×”×ª×¤×œ×’×•×ª: ×—×™×•×‘×™ {stats['positive_percentage']}%, ×©×œ×™×œ×™ {stats['negative_percentage']}%, × ×™×˜×¨×œ×™ {stats['neutral_percentage']}%")


# ============================================================================
# ×¤×•× ×§×¦×™×” ×¨××©×™×ª ×œ×”×¨×¦×ª ×›×œ ×”×“×•×’×××•×ª
# ============================================================================

def run_all_exam_scenarios():
    """×”×¨×¥ ××ª ×›×œ ×ª×¨×—×™×©×™ ×”××‘×—×Ÿ ×‘×‘×ª ××—×ª"""
    print("ğŸš€ ×ª×¨×—×™×©×™ ××‘×—×Ÿ - Data Science")
    print("=" * 50)

    try:
        # ×”×¦×’ ××” ×–××™×Ÿ ×‘××¢×¨×›×ª
        print("××¦×‘ ×”××¢×¨×›×ª:")
        print(f"  Sentiment analyzers: {get_available_sentiment_analyzers()}")
        print(f"  Text processors: {get_available_text_processors()}")
        print()

        # ×”×¨×¥ ××ª ×›×œ ×”×ª×¨×—×™×©×™×
        exam_scenario_specific_library()
        exam_scenario_stemming_lemmatization()
        exam_scenario_hebrew_processing()
        exam_scenario_model_comparison()
        exam_scenario_complete_pipeline()
        exam_scenario_troubleshooting()
        exam_scenario_advanced_features()

        print("\n" + "=" * 50)
        print("ğŸ‰ ×›×œ ×ª×¨×—×™×©×™ ×”××‘×—×Ÿ ×”×•×©×œ××• ×‘×”×¦×œ×—×”!")
        print("\n×¢×™×§×¨×™ ×”×œ×§×—×™× ×œ××‘×—×Ÿ:")
        print("  âœ… ×ª××™×“ ×™×© fallback ×œ×›×œ ×¡×¤×¨×™×™×”")
        print("  âœ… ×”×§×•×“ ×¢××™×“ ×‘×¤× ×™ ×©×’×™××•×ª")
        print("  âœ… ×ª××™×›×” ××œ××” ×‘×¢×‘×¨×™×ª")
        print("  âœ… ××’×•×•×Ÿ ×¨×—×‘ ×©×œ analyzers")
        print("  âœ… Pipeline ××œ× ×¢×•×‘×“ ×ª××™×“")

    except Exception as e:
        print(f"âŒ ×©×’×™××” ×‘×”×¨×¦×ª ×ª×¨×—×™×©×™ ×”××‘×—×Ÿ: {e}")
        logger.error(f"Exam scenarios failed: {e}", exc_info=True)


# ============================================================================
# ×¤×•× ×§×¦×™×•×ª ×¢×–×¨ ××”×™×¨×•×ª ×œ××‘×—×Ÿ
# ============================================================================

def quick_exam_demo(text: str = "This is an amazing product!"):
    """
    ×”×“×’××” ××”×™×¨×” ×œ×›×œ ×”×™×›×•×œ×•×ª - ××•×©×œ× ×œ××‘×—×Ÿ

    Args:
        text: ×˜×§×¡×˜ ×œ× ×™×ª×•×—
    """
    print(f"ğŸ¯ ×”×“×’××” ××”×™×¨×”: '{text}'")
    print("-" * 40)

    # Sentiment
    result = quick_sentiment_check(text)
    print(f"×¨×’×©: {result['label']} (×¦×™×•×Ÿ: {result.get('compound', 0):+.3f})")

    # Features
    features = extract_all_features(text)
    print(f"×˜×•×§× ×™×: {features.get('tokens', [])}")
    print(f"Stems: {features.get('stems', [])}")

    # Available tools
    print(f"×›×œ×™× ×–××™× ×™×: {get_available_sentiment_analyzers()}")


if __name__ == "__main__":
    # ×”×¨×¥ ×”×“×’××” ××”×™×¨×”
    quick_exam_demo()

    print("\n" + "=" * 60)

    # ×”×¨×¥ ××ª ×›×œ ×”×ª×¨×—×™×©×™×
    run_all_exam_scenarios()