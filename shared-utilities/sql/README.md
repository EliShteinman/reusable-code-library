# SQL Utils - ×¢×¨×›×ª ×›×œ×™× ×ž×§×¦×•×¢×™×ª ×œ-SQL

×¢×¨×›×ª ×›×œ×™× ×ž×œ××” ×¢× ×”×¤×¨×“×” ×ž×•×©×œ×ž×ª ×‘×™×Ÿ clients ×•-repository, ×ª×ž×™×›×” ×‘-MySQL ×•-PostgreSQL.

## ðŸ“ ×ž×‘× ×” ×”×§×‘×¦×™× - CLEAN ARCHITECTURE

```
shared-utilities/sql/
â”œâ”€â”€ __init__.py                      # ×™×‘×•××™× ×•×¤×•× ×§×¦×™×•×ª ×ž×”×™×¨×•×ª
â”œâ”€â”€ mysql_sync_client.py             # MySQL connection client (CONNECTION ONLY)
â”œâ”€â”€ postgresql_sync_client.py        # PostgreSQL connection client (CONNECTION ONLY)  
â”œâ”€â”€ sql_repository.py                # Repository ××—×“ (CRUD ONLY - ×¢×•×‘×“ ×¢× ×©× ×™ ×”clients)
â”œâ”€â”€ examples.py                      # ×“×•×’×ž××•×ª ×ž×§×™×¤×•×ª ×œ×ž×‘×—×Ÿ
â””â”€â”€ README.md                        # ×”×ž×“×¨×™×š ×”×–×”
```

## ðŸš€ ×”×ª×§× ×” ×ž×”×™×¨×”

```bash
# MySQL
pip install mysql-connector-python

# PostgreSQL  
pip install psycopg2-binary

# Pandas integration
pip install pandas
```

## ðŸŽ¯ ×”×¢×§×¨×•× ×•×ª ×”×—×“×©×™× - FIXED ARCHITECTURE

### âœ… **×”×”×¤×¨×“×” ×”×ž×•×©×œ×ž×ª:**
- **Connection Clients:** ×¨×§ ×—×™×‘×•×¨ ×•×¤×¢×•×œ×•×ª RAW SQL (`execute_*`)
- **SQL Repository:** ×¨×§ ×œ×•×’×™×§×” ×¢×¡×§×™×ª (`create`, `search`, `join`, `aggregate`)
- **Repository ××—×“:** ×¢×•×‘×“ ×¢× MySQL ×•-PostgreSQL!
- **××™×Ÿ ×¢×•×“ runtime detection ×ž×›×•×¢×¨!**

### âŒ **×ž×” ×ª×™×§× ×•:**
- âŒ ××™×Ÿ ×™×•×ª×¨ 3 repositories ×©×•× ×™×
- âŒ ××™×Ÿ ×™×•×ª×¨ ×§×•×‘×¥ ×¢× ×§ ×©×œ 450+ ×©×•×¨×•×ª
- âŒ ××™×Ÿ ×™×•×ª×¨ ×‘×œ×’×Ÿ ×©×œ CRUD ×‘-client

---

## ðŸ“Š ×ž×” ×–×” SQL? - ×œ×ž×‘×—×Ÿ

### **SQL vs NoSQL:**
| SQL Database | â†’ | NoSQL Database |
|-------------|---|----------------|
| Table       | â†’ | Collection/Document |
| Row         | â†’ | Document/Record |
| Column      | â†’ | Field/Property |
| Schema      | â†’ | Schema-less |
| ACID        | â†’ | BASE |
| JOIN        | â†’ | Embed/Reference |
| Normalization | â†’ | Denormalization |

### **×ž×•×©×’×™ ×™×¡×•×“ ×œ×ž×‘×—×Ÿ:**
- **Primary Key** - ×ž×¤×ª×— ×™×™×—×•×“×™ ×©×œ ×”×˜×‘×œ×”
- **Foreign Key** - ×ž×¤×ª×— ×”×ž×§×©×¨ ×‘×™×Ÿ ×˜×‘×œ××•×ª
- **Index** - ×œ×©×™×¤×•×¨ ×‘×™×¦×•×¢×™ ×—×™×¤×•×©
- **Transaction** - ×§×‘×•×¦×ª ×¤×¢×•×œ×•×ª ×©×ž×ª×‘×¦×¢×•×ª ×™×—×“ ××• ×‘×›×œ×œ ×œ×
- **ACID** - Atomicity, Consistency, Isolation, Durability
- **JOIN** - ×—×™×‘×•×¨ ×‘×™×Ÿ ×˜×‘×œ××•×ª (INNER, LEFT, RIGHT, FULL)
- **Aggregation** - ×¤×•× ×§×¦×™×•×ª ×¦×‘×™×¨×” (COUNT, SUM, AVG, MIN, MAX)
- **Normalization** - ×ª×§×™× ×•×Ÿ ×”× ×ª×•× ×™× ×œ×ž× ×™×¢×ª ×›×¤×™×œ×•×™×•×ª

---

## ðŸ”§ ×©×™×ž×•×© ×‘×¡×™×¡×™ - MySQL

### 1. ×”×§×ž×” ×ž×”×™×¨×”
```python
from shared_utilities.sql import MySQLSyncClient, SQLRepository

# ×™×¦×™×¨×ª client (CONNECTION ONLY) ×•-repository (CRUD ONLY)
client = MySQLSyncClient("localhost", "user", "password", "test_db")
repo = SQLRepository(client, "users")

# ×™×¦×™×¨×ª ×˜×‘×œ×”
create_table = """
CREATE TABLE IF NOT EXISTS users (
    id INT AUTO_INCREMENT PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    age INT,
    city VARCHAR(50),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
)
"""
client.execute_query(create_table, fetch=False)
```

### 2. CRUD ×‘×¡×™×¡×™
```python
# CREATE - ×™×¦×™×¨×ª record
user_id = repo.create({
    "name": "John Doe",
    "email": "john@example.com",
    "age": 30,
    "city": "Tel Aviv"
})
print(f"Created user: {user_id}")

# READ - ×§×¨×™××ª record
user = repo.get_by_id(user_id)
print(f"User: {user['name']} - {user['email']}")

# UPDATE - ×¢×“×›×•×Ÿ record  
updated = repo.update(user_id, {
    "age": 31,
    "city": "Jerusalem"
})
print(f"Updated: {updated} rows affected")

# DELETE - ×ž×—×™×§×ª record
deleted = repo.delete(user_id)
print(f"Deleted: {deleted} rows affected")
```

### 3. ×—×™×¤×•×© ×ž×ª×§×“× - Query Building System
```python
# ×—×™×¤×•×© ×ž×“×•×™×§ (exact match)
tel_aviv_users = repo.search(
    filters={"city": "Tel Aviv", "age": 30},
    limit=10
)
print(f"Found {tel_aviv_users['total_count']} users")

# ×—×™×¤×•×© ×˜×•×•×— (range filters)
adults = repo.search(
    filters={"age": {"gte": 18, "lte": 65}},
    limit=15,
    order_by="age",
    order_dir="ASC"
)

# ×—×™×¤×•×© ×‘×¨×©×™×ž×” (IN filters)
cities_users = repo.search(
    filters={"city": ["Tel Aviv", "Jerusalem", "Haifa"]},
    limit=20
)

# ×—×™×¤×•×© LIKE patterns
gmail_users = repo.search(
    filters={"email": "%@gmail.com"},
    limit=10
)

# ×—×™×¤×•×© ×ž×©×•×œ×‘ - ×›×œ ×”×¤×™×œ×˜×¨×™× ×‘×™×—×“
filtered_results = repo.search(
    filters={
        "city": ["Tel Aviv", "Jerusalem"],  # IN filter
        "age": {"gte": 25, "lte": 40},      # Range filter
        "email": "%@company.com"            # LIKE filter
    },
    order_by="age",
    order_dir="DESC",
    limit=10,
    offset=0
)
```

### 4. Bulk Operations - ×¢×™×‘×•×“ ×ž×¡×™×‘×™
```python
# Bulk create - ×™×¦×™×¨×” ×ž×¡×™×‘×™×ª (×”×›×™ ×™×¢×™×œ!)
users = [
    {"name": "Alice", "age": 25, "city": "Tel Aviv", "email": "alice@example.com"},
    {"name": "Bob", "age": 30, "city": "Jerusalem", "email": "bob@example.com"},
    {"name": "Carol", "age": 35, "city": "Haifa", "email": "carol@example.com"}
]
result = repo.bulk_create(users)
print(f"Created: {result['success_count']}/{len(users)} users")

# Bulk update - ×¢×“×›×•×Ÿ ×ž×¡×™×‘×™
updates = [
    {"filters": {"city": "Tel Aviv"}, "data": {"city": "Tel Aviv-Yafo"}},
    {"filters": {"age": {"lt": 25}}, "data": {"status": "young"}}
]
result = repo.bulk_update(updates)
print(f"Updated: {result['success_count']} operations")

# Bulk delete - ×ž×—×™×§×” ×ž×¡×™×‘×™×ª
filters_to_delete = [
    {"status": "inactive"},
    {"age": {"lt": 18}}
]
result = repo.bulk_delete(filters_to_delete)
print(f"Deleted: {result['success_count']} operations")
```

---

## ðŸ˜ ×©×™×ž×•×© ×¢× PostgreSQL

### ×”×’×“×¨×ª PostgreSQL
```python
from shared_utilities.sql import PostgreSQLSyncClient, SQLRepository

# ×™×¦×™×¨×ª PostgreSQL client ×•-repository
client = PostgreSQLSyncClient("localhost", "user", "password", "test_db")
repo = SQLRepository(client, "products")

# ×™×¦×™×¨×ª ×˜×‘×œ×” ×¢× PostgreSQL features
create_table = """
CREATE TABLE IF NOT EXISTS products (
    id SERIAL PRIMARY KEY,
    product_name VARCHAR(100) NOT NULL,
    description TEXT,
    price DECIMAL(10,2),
    tags TEXT[],  -- PostgreSQL array
    data JSONB,   -- PostgreSQL JSON
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
)
"""
client.execute_query(create_table, fetch=False)

# PostgreSQL ×©×™×ž×•×© ×–×”×” ×œ×—×œ×•×˜×™×Ÿ!
product_id = repo.create({
    "product_name": "Gaming Laptop",
    "description": "High-performance laptop",
    "price": 4999.99
})

# ×—×™×¤×•×© ×–×”×”
products = repo.search(
    filters={"price": {"gte": 1000}},
    limit=10
)
```

---

## ðŸ”— JOIN Operations - ×—×™×‘×•×¨×™× ×‘×™×Ÿ ×˜×‘×œ××•×ª

### JOIN ×‘×¡×™×¡×™
```python
# INNER JOIN - ×¨×§ records ×©×™×© ×œ×”× ×”×ª××ž×”
users_with_orders = users_repo.inner_join(
    "orders",
    "users.id = orders.user_id",
    limit=10
)

# LEFT JOIN - ×›×œ ×”×ž×©×ª×ž×©×™×, ×’× ××œ×” ×‘×œ×™ ×”×–×ž× ×•×ª
all_users = users_repo.left_join(
    "orders", 
    "users.id = orders.user_id",
    limit=20
)

# JOIN ×¢× ×¤×™×œ×˜×¨×™×
tel_aviv_orders = users_repo.inner_join(
    "orders",
    "users.id = orders.user_id",
    filters={"users.city": "Tel Aviv", "orders.status": "completed"},
    limit=10
)
```

### JOIN ×ž×•×¨×›×‘ ×œ×ž×‘×—×Ÿ
```python
# ×¡×˜×˜×™×¡×˜×™×§×•×ª ×ž×©×ª×ž×©×™× ×¢× ×”×–×ž× ×•×ª
user_stats = client.execute_query("""
SELECT 
    u.name,
    u.city,
    COUNT(o.id) as order_count,
    COALESCE(SUM(o.amount), 0) as total_spent,
    COALESCE(AVG(o.amount), 0) as avg_order_value
FROM users u
LEFT JOIN orders o ON u.id = o.user_id
GROUP BY u.id, u.name, u.city
ORDER BY total_spent DESC
""")

for stat in user_stats:
    name = stat['name']
    city = stat['city']
    orders = stat['order_count']
    total = stat['total_spent']
    avg = stat['avg_order_value']
    print(f"{name} ({city}): {orders} orders, ${total:.2f} total, ${avg:.2f} avg")
```

---

## ðŸ“Š Aggregations - × ×™×ª×•×—×™× ×•×¡×˜×˜×™×¡×˜×™×§×•×ª

### ××’×¨×’×¦×™×•×ª × ×¤×•×¦×•×ª ×œ×ž×‘×—×Ÿ
```python
# 1. GROUP BY ×¢× COUNT (×›×ž×• ×‘MongoDB)
dept_stats = repo.aggregate(
    "department, COUNT(*) as employee_count, AVG(salary) as avg_salary",
    group_by="department"
)

for result in dept_stats:
    dept = result['department']
    count = result['employee_count']
    avg_salary = result['avg_salary']
    print(f"{dept}: {count} employees, avg salary: {avg_salary:.2f}")

# 2. ×¡×˜×˜×™×¡×˜×™×§×•×ª ×‘×¡×™×¡×™×•×ª (min, max, avg, sum)
stats = repo.aggregate(
    "MIN(salary) as min_salary, MAX(salary) as max_salary, AVG(salary) as avg_salary, SUM(salary) as total_salary"
)
print(f"Salary stats: min={stats[0]['min_salary']}, max={stats[0]['max_salary']}")

# 3. ×¤×•× ×§×¦×™×•×ª × ×•×—×•×ª
total_salary = repo.sum("salary")  # SUM
avg_age = repo.avg("age")          # AVG
salary_range = repo.min_max("salary")  # MIN & MAX
dept_counts = repo.group_by_count("department")  # GROUP BY + COUNT

# 4. HAVING clause
high_salary_depts = repo.aggregate(
    "department, AVG(salary) as avg_salary, COUNT(*) as employee_count",
    group_by="department",
    having="AVG(salary) > 15000"
)

# 5. ×¡×¤×™×¨×” ×¤×©×•×˜×”
total_count = repo.count()
active_count = repo.count({"active": True})
tel_aviv_count = repo.count({"city": "Tel Aviv"})
```

---

## ðŸ¼ ××™× ×˜×’×¨×¦×™×” ×¢× Pandas

### DataFrame â†” SQL
```python
import pandas as pd

# 1. ×™×¦×™×¨×ª × ×ª×•× ×™× ×‘-DataFrame
df = pd.DataFrame({
    'user_id': ['U001', 'U002', 'U003'],
    'name': ['Alice', 'Bob', 'Carol'],
    'age': [25, 30, 35],
    'city': ['Tel Aviv', 'Jerusalem', 'Haifa'],
    'salary': [15000, 18000, 20000]
})

# 2. ×”×¢×œ××” ×ž-DataFrame ×œ-SQL
result = repo.bulk_create_from_dataframe(df, id_column='user_id')
print(f"Uploaded: {result['success_count']} records")

# 3. ×”×•×¨×“×” ×ž-SQL ×œ-DataFrame
search_df = repo.to_dataframe(
    filters={"city": "Tel Aviv", "salary": {"gte": 15000}},
    limit=100
)

# 4. × ×™×ª×•×— ×¢× pandas
if not search_df.empty:
    avg_salary = search_df['salary'].mean()
    city_counts = search_df['city'].value_counts()
    age_groups = search_df.groupby('city')['age'].mean()
    
    print(f"Average salary: {avg_salary:.2f}")
    print("City distribution:")
    print(city_counts)
    print("Average age by city:")
    print(age_groups)

# 5. DataFrame analysis
analysis = repo.from_dataframe_analysis(search_df)
print(f"DataFrame analysis: {analysis['total_rows']} rows, {len(analysis['columns'])} columns")
```

---

## ðŸ’¾ Transactions - ×¢×§×‘×™×•×ª × ×ª×•× ×™×

### Transaction ×‘×¡×™×¡×™
```python
# Transaction ×ž×•×¦×œ×—
try:
    with repo.transaction() as conn:
        cursor = conn.cursor()
        
        # ×”×¢×‘×¨×ª ×›×¡×£ ×‘×™×Ÿ ×—×©×‘×•× ×•×ª
        cursor.execute(
            "UPDATE accounts SET balance = balance - %s WHERE account_id = %s",
            (500.00, "ACC001")
        )
        
        cursor.execute(
            "UPDATE accounts SET balance = balance + %s WHERE account_id = %s", 
            (500.00, "ACC002")
        )
        
        # Transaction ×™×ª×‘×¦×¢ ××•×˜×•×ž×˜×™×ª
        print("âœ… Transfer completed")
        
except Exception as e:
    print(f"âŒ Transaction failed and rolled back: {e}")
```

### Transaction ×¢× rollback
```python
try:
    with repo.transaction() as conn:
        cursor = conn.cursor()
        
        # × ×™×¡×™×•×Ÿ ×œ×”×¢×‘×™×¨ ×™×•×ª×¨ ×›×¡×£ ×ž×”×–×ž×™×Ÿ
        cursor.execute(
            "UPDATE accounts SET balance = balance - %s WHERE account_id = %s AND balance >= %s",
            (10000.00, "ACC001", 10000.00)
        )
        
        if cursor.rowcount == 0:
            raise ValueError("Insufficient funds")
            
        # ×× ×”×’×¢× ×• ×œ×›××Ÿ - ×”×›×¡×£ ×ž×¡×¤×™×§
        cursor.execute(
            "UPDATE accounts SET balance = balance + %s WHERE account_id = %s",
            (10000.00, "ACC002")
        )
        
except Exception as e:
    print(f"âœ… Transaction rolled back: {e}")
```

---

## ðŸŽ¯ ×“×¤×•×¡×™× × ×¤×•×¦×™× ×œ×ž×‘×—×Ÿ

### 1. ×—×™×¤×•×© ×ž×•×¨×›×‘ ×¢× JOIN
```python
# ×©××œ×ª ×ž×‘×—×Ÿ: "×ž×¦× ×ž×©×ª×ž×©×™× ×ž×ª×œ ××‘×™×‘ ×¢× ×”×–×ž× ×•×ª ×ž×¢×œ 1000â‚ª"
results = users_repo.inner_join(
    "orders",
    "users.id = orders.user_id",
    filters={
        "users.city": "Tel Aviv",
        "orders.amount": {"gte": 1000},
        "orders.status": "completed"
    },
    limit=20
)
```

### 2. × ×™×ª×•×— × ×ª×•× ×™× ×¢× GROUP BY
```python
# ×©××œ×ª ×ž×‘×—×Ÿ: "×—×©×‘ ×¡×š ×”×›× ×¡×•×ª ×œ×¤×™ ×—×•×“×© ×•×ž×¦× ×”×—×•×“×© ×”×˜×•×‘ ×‘×™×•×ª×¨"
monthly_revenue = repo.aggregate(
    "YEAR(order_date) as year, MONTH(order_date) as month, SUM(amount) as total_revenue, COUNT(*) as order_count",
    group_by="YEAR(order_date), MONTH(order_date)",
    filters={"status": "completed"}
)

# ×ž×™×•×Ÿ ×œ×¤×™ ×”×›× ×¡×•×ª (Python)
sorted_months = sorted(monthly_revenue, key=lambda x: x['total_revenue'], reverse=True)
best_month = sorted_months[0]
print(f"Best month: {best_month['year']}-{best_month['month']:02d} with ${best_month['total_revenue']:,.2f}")
```

### 3. Bulk Operations ×¢× validation
```python
# ×©××œ×ª ×ž×‘×—×Ÿ: "×”×¢×œ×” 1000 ×¢×•×‘×“×™× ×ž×§×•×‘×¥ CSV ×¢× validation"
import pandas as pd

# ×§×¨×™××ª CSV
df = pd.read_csv("employees.csv")

# × ×™×§×•×™ × ×ª×•× ×™×
df = df.dropna()
df['salary'] = pd.to_numeric(df['salary'], errors='coerce')
df = df[df['salary'] > 0]  # ×•×•×™×“×•× ×©×›×¨ ×—×™×•×‘×™

# validation × ×•×¡×£
valid_cities = ['Tel Aviv', 'Jerusalem', 'Haifa', 'Beer Sheva']
df = df[df['city'].isin(valid_cities)]

# ×”×¢×œ××” ×ž×¡×™×‘×™×ª
result = repo.bulk_create_from_dataframe(df, id_column='employee_id')
print(f"Success: {result['success_count']}, Errors: {result['error_count']}")
```

### 4. Complex JOIN ×¢× aggregation
```python
# ×©××œ×ª ×ž×‘×—×Ÿ: "×“×•"×— ×ž×›×™×¨×•×ª ×ž×œ× ×¢× ×œ×§×•×—×•×ª ×•×ž×•×¦×¨×™×"
sales_report = client.execute_query("""
SELECT 
    c.name as customer_name,
    c.city,
    p.product_name,
    p.category,
    SUM(oi.quantity) as total_quantity,
    SUM(oi.price * oi.quantity) as total_revenue,
    COUNT(DISTINCT o.id) as order_count
FROM customers c
JOIN orders o ON c.id = o.customer_id
JOIN order_items oi ON o.id = oi.order_id  
JOIN products p ON oi.product_id = p.id
WHERE o.order_date >= %s
GROUP BY c.id, c.name, c.city, p.id, p.product_name, p.category
HAVING SUM(oi.price * oi.quantity) > %s
ORDER BY total_revenue DESC
""", (datetime.now().date() - timedelta(days=90), 1000))

for report in sales_report:
    customer = report['customer_name']
    city = report['city']
    product = report['product_name']
    revenue = report['total_revenue']
    orders = report['order_count']
    print(f"{customer} ({city}) - {product}: {orders} orders, ${revenue:,.2f}")
```

---

## âš¡ ×¤×•× ×§×¦×™×•×ª ×ž×”×™×¨×•×ª ×œ×ž×‘×—×Ÿ

### Setup ×ž×”×™×¨
```python
# MySQL
from shared_utilities.sql import setup_mysql
client, repo = setup_mysql("localhost", "user", "password", "test_db", "users")

# PostgreSQL
from shared_utilities.sql import setup_postgresql
client, repo = setup_postgresql("localhost", "user", "password", "test_db", "users")
```

### ×¤×§×•×“×•×ª ×—×™×•× ×™×•×ª
```python
# ×™×¦×™×¨×” ×ž×”×™×¨×”
user_id = repo.create({"name": "Test", "age": 25, "city": "Tel Aviv"})

# ×—×™×¤×•×© ×ž×”×™×¨
results = repo.search(filters={"city": "Tel Aviv"}, limit=5)

# ×¡×¤×™×¨×” ×ž×”×™×¨×”  
count = repo.count(filters={"active": True})

# ××’×¨×’×¦×™×” ×ž×”×™×¨×”
stats = repo.aggregate("AVG(age) as avg_age, COUNT(*) as total")

# JOIN ×ž×”×™×¨
joined = repo.inner_join("orders", "users.id = orders.user_id", limit=10)

# DataFrame ×ž×”×™×¨
df = repo.to_dataframe(limit=100)

# Transaction ×ž×”×™×¨
with repo.transaction() as conn:
    cursor = conn.cursor()
    cursor.execute("UPDATE users SET active = TRUE WHERE city = %s", ("Tel Aviv",))
```

---

## ðŸš¨ ×©×’×™××•×ª × ×¤×•×¦×•×ª ×•×¤×ª×¨×•× ×•×ª

### 1. ×‘×¢×™×•×ª ×—×™×‘×•×¨
```python
# MySQL ×œ× ×¨×¥
# ×¤×ª×¨×•×Ÿ: systemctl start mysql
# ××•: brew services start mysql

# PostgreSQL ×œ× ×¨×¥  
# ×¤×ª×¨×•×Ÿ: systemctl start postgresql
# ××•: brew services start postgresql
```

### 2. ×˜×‘×œ×” ×œ× ×§×™×™×ž×ª
```python
# ×™×¦×™×¨×ª ×˜×‘×œ×” ×× ×œ× ×§×™×™×ž×ª
create_table = """
CREATE TABLE IF NOT EXISTS users (
    id SERIAL PRIMARY KEY,  -- PostgreSQL
    -- ××• --
    id INT AUTO_INCREMENT PRIMARY KEY,  -- MySQL
    name VARCHAR(100) NOT NULL
)
"""
client.execute_query(create_table, fetch=False)
```

### 3. Foreign Key constraints
```python
# ×™×¦×™×¨×ª ×˜×‘×œ××•×ª ×‘×¡×“×¨ ×”× ×›×•×Ÿ
create_users = "CREATE TABLE users (id INT PRIMARY KEY, name VARCHAR(100))"
create_orders = """
CREATE TABLE orders (
    id INT PRIMARY KEY,
    user_id INT,
    FOREIGN KEY (user_id) REFERENCES users(id)
)
"""
```

### 4. ×©×’×™××•×ª JOIN
```python
# ×‘×“×™×§×ª × ×ª×•× ×™× ×œ×¤× ×™ JOIN
users_count = users_repo.count()
orders_count = orders_repo.count()
print(f"Users: {users_count}, Orders: {orders_count}")

# JOIN ×¢× COALESCE ×œ×ž× ×™×¢×ª NULL
safe_join = client.execute_query("""
SELECT u.name, COALESCE(COUNT(o.id), 0) as order_count
FROM users u LEFT JOIN orders o ON u.id = o.user_id
GROUP BY u.id, u.name
""")
```

---

## ðŸ“ ×˜×™×¤×™× ×œ×ž×‘×—×Ÿ

### ×ž×” ×—×©×•×‘ ×œ×“×¢×ª:
1. **SQL Operators:** `=`, `!=`, `>`, `>=`, `<`, `<=`, `IN`, `LIKE`, `BETWEEN`, `IS NULL`
2. **JOIN Types:** `INNER`, `LEFT`, `RIGHT`, `FULL OUTER`
3. **Aggregation Functions:** `COUNT`, `SUM`, `AVG`, `MIN`, `MAX`, `GROUP BY`, `HAVING`
4. **Transactions:** `BEGIN`, `COMMIT`, `ROLLBACK`, `ACID`
5. **Indexes:** `PRIMARY KEY`, `FOREIGN KEY`, `UNIQUE`, `INDEX`

### ×“×¤×•×¡×™ ×§×•×“ ×©×—×•×–×¨×™× ×‘×ž×‘×—× ×™×:
```python
# 1. ×™×¦×™×¨×ª repository
client = MySQLSyncClient("localhost", "user", "password", "db_name")
repo = SQLRepository(client, "table_name")

# 2. ×—×™×¤×•×© ×ž×©×•×œ×‘
results = repo.search(
    filters={"field": "value", "age": {"gte": 18}},
    limit=10
)

# 3. ××’×¨×’×¦×™×” ×‘×¡×™×¡×™×ª
stats = repo.aggregate(
    "field, COUNT(*) as count, AVG(value) as average",
    group_by="field"
)

# 4. JOIN ×¢× ×¤×™×œ×˜×¨×™×
joined = repo.inner_join(
    "other_table",
    "table.id = other_table.foreign_id",
    filters={"field": "value"}
)

# 5. DataFrame integration
df = repo.to_dataframe()
repo.bulk_create_from_dataframe(df)

# 6. Transaction
with repo.transaction() as conn:
    cursor = conn.cursor()
    cursor.execute("UPDATE ...", params)
```

**×‘×”×¦×œ×—×” ×‘×ž×‘×—×Ÿ! ðŸŽ¯**

---

## ðŸ”§ Troubleshooting ×ž×”×™×¨

| ×‘×¢×™×” | ×¤×ª×¨×•×Ÿ |
|------|--------|
| Connection refused | `systemctl start mysql/postgresql` |
| Table doesn't exist | `CREATE TABLE IF NOT EXISTS ...` |
| Foreign key error | ×™×¦×™×¨×ª parent table ×§×•×“× |
| JOIN returns empty | ×‘×“×•×§ ×©×™×© × ×ª×•× ×™× ×‘×©×ª×™ ×”×˜×‘×œ××•×ª |
| Transaction failed | ×‘×“×•×§ ACID constraints |

**×–×” ×”×›×œ! SQL ×ž×•×›×Ÿ ×œ×ž×‘×—×Ÿ! ðŸš€**